{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38b76a3-623c-41da-8e2c-310350caf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5f292c-eaab-45cf-8d64-c428319f4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\yana1\\\\Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf2edf0-a18e-464e-810e-7f3be13bb1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_numeric</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>gender_guessed</th>\n",
       "      <th>gallery</th>\n",
       "      <th>painting</th>\n",
       "      <th>is_signed</th>\n",
       "      <th>age</th>\n",
       "      <th>years_selling</th>\n",
       "      <th>location</th>\n",
       "      <th>image_path</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3158.0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>27.6</td>\n",
       "      <td>Unique</td>\n",
       "      <td>female</td>\n",
       "      <td>independent</td>\n",
       "      <td>other</td>\n",
       "      <td>signed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>France</td>\n",
       "      <td>images_thesis\\2313827_1_m.jpg</td>\n",
       "      <td>https://www.artsper.com/us/contemporary-artwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2065.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>Unique</td>\n",
       "      <td>female</td>\n",
       "      <td>independent</td>\n",
       "      <td>other</td>\n",
       "      <td>signed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>France</td>\n",
       "      <td>images_thesis\\2328028_1_m.jpg</td>\n",
       "      <td>https://www.artsper.com/us/contemporary-artwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3522.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>Unique</td>\n",
       "      <td>female</td>\n",
       "      <td>independent</td>\n",
       "      <td>other</td>\n",
       "      <td>signed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>France</td>\n",
       "      <td>images_thesis\\2299335_1_m.jpg</td>\n",
       "      <td>https://www.artsper.com/us/contemporary-artwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>644.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>Unique</td>\n",
       "      <td>female</td>\n",
       "      <td>gallery</td>\n",
       "      <td>oil</td>\n",
       "      <td>signed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>other</td>\n",
       "      <td>images_thesis\\1118562_1_m.jpg</td>\n",
       "      <td>https://www.artsper.com/us/contemporary-artwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>838.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>Unique</td>\n",
       "      <td>unknown</td>\n",
       "      <td>independent</td>\n",
       "      <td>other</td>\n",
       "      <td>signed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>France</td>\n",
       "      <td>images_thesis\\1241121_1_m.jpg</td>\n",
       "      <td>https://www.artsper.com/us/contemporary-artwor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_numeric  Height  Width Uniqueness gender_guessed      gallery  \\\n",
       "0         3158.0    27.6   27.6     Unique         female  independent   \n",
       "1         2065.0    19.7   19.7     Unique         female  independent   \n",
       "2         3522.0    23.6   23.6     Unique         female  independent   \n",
       "3          644.0    15.7   11.8     Unique         female      gallery   \n",
       "4          838.0    15.7   15.7     Unique        unknown  independent   \n",
       "\n",
       "  painting is_signed  age  years_selling location  \\\n",
       "0    other    signed  0.0            1.0   France   \n",
       "1    other    signed  0.0            3.0   France   \n",
       "2    other    signed  0.0            3.0   France   \n",
       "3      oil    signed  4.0            5.0    other   \n",
       "4    other    signed  4.0            5.0   France   \n",
       "\n",
       "                      image_path  \\\n",
       "0  images_thesis\\2313827_1_m.jpg   \n",
       "1  images_thesis\\2328028_1_m.jpg   \n",
       "2  images_thesis\\2299335_1_m.jpg   \n",
       "3  images_thesis\\1118562_1_m.jpg   \n",
       "4  images_thesis\\1241121_1_m.jpg   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.artsper.com/us/contemporary-artwor...  \n",
       "1  https://www.artsper.com/us/contemporary-artwor...  \n",
       "2  https://www.artsper.com/us/contemporary-artwor...  \n",
       "3  https://www.artsper.com/us/contemporary-artwor...  \n",
       "4  https://www.artsper.com/us/contemporary-artwor...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('thesisdata_cleaned_fullsample1.csv')\n",
    "\n",
    "data = data.drop(columns = ['Unnamed: 0'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d589f59-b838-4385-9c2d-63e9f3068195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (13404, 15)\n",
      "Val shape: (2873, 15)\n",
      "Test shape: (2855, 15)\n",
      "CNN Train: (13404, 2)\n",
      "CNN Val: (2873, 2)\n",
      "CNN Test: (2855, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# ===============================\n",
    "# 1) Copy & remove UNUSED columns (BUT KEEP image_path!)\n",
    "# ===============================\n",
    "df = data.copy()\n",
    "df = df.drop(columns=[\"url\"])    # DO NOT drop image_path\n",
    "\n",
    "target = \"price_numeric\"\n",
    "numeric = [\"Height\", \"Width\", \"age\", \"years_selling\"]\n",
    "categorical = [\"Uniqueness\", \"gender_guessed\", \"gallery\", \"painting\", \"is_signed\", \"location\"]\n",
    "\n",
    "# ===============================\n",
    "# 2) Initial Train/Test split FIRST\n",
    "# ===============================\n",
    "df_train, df_test = train_test_split(df, test_size=0.15, random_state=123)\n",
    "\n",
    "# ===============================\n",
    "# 3) Compute Tukey limits using TRAIN ONLY\n",
    "# ===============================\n",
    "Q1 = df_train[target].quantile(0.25)\n",
    "Q3 = df_train[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "# ===============================\n",
    "# 4) Remove outliers from TRAIN ONLY\n",
    "# ===============================\n",
    "df_train = df_train[(df_train[target] >= lower) & (df_train[target] <= upper)]\n",
    "\n",
    "# ===============================\n",
    "# 5) Remove test outliers using TRAIN thresholds (NO leakage)\n",
    "# ===============================\n",
    "df_test = df_test[(df_test[target] >= lower) & (df_test[target] <= upper)]\n",
    "\n",
    "# ===============================\n",
    "# 6) Train/Validation split (AFTER cleaning)\n",
    "# ===============================\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1765, random_state=123)\n",
    "\n",
    "# ===============================\n",
    "# 7) EXTRACT raw X/y FOR MLP (image_path EXCLUDED)\n",
    "# ===============================\n",
    "X_train_raw = df_train[numeric + categorical]   # image_path NOT included\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_val_raw = df_val[numeric + categorical]\n",
    "y_val = df_val[target]\n",
    "\n",
    "X_test_raw = df_test[numeric + categorical]\n",
    "y_test = df_test[target]\n",
    "\n",
    "# ===============================\n",
    "# 8) One-hot encoding (FIT ON TRAIN ONLY)\n",
    "# ===============================\n",
    "X_train = pd.get_dummies(X_train_raw, columns=categorical, drop_first=True)\n",
    "X_val   = pd.get_dummies(X_val_raw,   columns=categorical, drop_first=True)\n",
    "X_test  = pd.get_dummies(X_test_raw,  columns=categorical, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "X_val  = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# ===============================\n",
    "# 9) Scale numeric features using RobustScaler (FIT ON TRAIN ONLY)\n",
    "# ===============================\n",
    "scaler = RobustScaler()\n",
    "X_train[numeric] = scaler.fit_transform(X_train[numeric])\n",
    "X_val[numeric]   = scaler.transform(X_val[numeric])\n",
    "X_test[numeric]  = scaler.transform(X_test[numeric])\n",
    "\n",
    "# ===============================\n",
    "# Final shapes for MLP\n",
    "# ===============================\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape:\",   X_val.shape)\n",
    "print(\"Test shape:\",  X_test.shape)\n",
    "\n",
    "# ===============================\n",
    "# SAVE CNN DATASETS (WITH image_path)\n",
    "# ===============================\n",
    "df_train_cnn = df_train[['image_path', target]].copy()\n",
    "df_val_cnn   = df_val[['image_path', target]].copy()\n",
    "df_test_cnn  = df_test[['image_path', target]].copy()\n",
    "\n",
    "print(\"CNN Train:\", df_train_cnn.shape)\n",
    "print(\"CNN Val:\",   df_val_cnn.shape)\n",
    "print(\"CNN Test:\",  df_test_cnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d1f9c72-3608-4d2e-8e54-0bcf1bd86a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "\n",
    "    # Block 1\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    # Block 2\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    # Block 3\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fd30c90-d7e9-467c-8909-3c6c6369433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1845.1415 - mae: 1845.6415 - val_loss: 1816.2614 - val_mae: 1816.7614 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1841.1925 - mae: 1841.6925 - val_loss: 1811.3721 - val_mae: 1811.8721 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1833.6604 - mae: 1834.1604 - val_loss: 1802.1636 - val_mae: 1802.6636 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1822.4445 - mae: 1822.9445 - val_loss: 1789.1063 - val_mae: 1789.6063 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1807.6182 - mae: 1808.1182 - val_loss: 1771.6996 - val_mae: 1772.1996 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1789.2981 - mae: 1789.7981 - val_loss: 1742.5667 - val_mae: 1743.0667 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1767.6121 - mae: 1768.1121 - val_loss: 1711.4016 - val_mae: 1711.9016 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1742.6812 - mae: 1743.1812 - val_loss: 1668.1562 - val_mae: 1668.6562 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1714.6196 - mae: 1715.1196 - val_loss: 1645.0240 - val_mae: 1645.5240 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1683.5598 - mae: 1684.0598 - val_loss: 1608.8188 - val_mae: 1609.3188 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1649.5586 - mae: 1650.0586 - val_loss: 1584.2008 - val_mae: 1584.7008 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1612.8168 - mae: 1613.3168 - val_loss: 1524.6522 - val_mae: 1525.1522 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1573.4086 - mae: 1573.9086 - val_loss: 1486.8993 - val_mae: 1487.3993 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1531.4828 - mae: 1531.9830 - val_loss: 1448.4611 - val_mae: 1448.9611 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1487.1595 - mae: 1487.6595 - val_loss: 1405.9069 - val_mae: 1406.4069 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1440.7032 - mae: 1441.2032 - val_loss: 1359.7236 - val_mae: 1360.2236 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1392.0795 - mae: 1392.5795 - val_loss: 1311.2538 - val_mae: 1311.7538 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1342.3390 - mae: 1342.8390 - val_loss: 1275.2998 - val_mae: 1275.7998 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1291.2740 - mae: 1291.7740 - val_loss: 1232.1823 - val_mae: 1232.6821 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1240.2832 - mae: 1240.7831 - val_loss: 1163.9065 - val_mae: 1164.4065 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188.1691 - mae: 1188.6689 - val_loss: 1125.3330 - val_mae: 1125.8325 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1137.3231 - mae: 1137.8230 - val_loss: 1082.7378 - val_mae: 1083.2374 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1086.8318 - mae: 1087.3315 - val_loss: 1054.0978 - val_mae: 1054.5975 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1037.9155 - mae: 1038.4153 - val_loss: 995.8669 - val_mae: 996.3665 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 990.9781 - mae: 991.4779 - val_loss: 958.6567 - val_mae: 959.1566 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 944.8776 - mae: 945.3773 - val_loss: 943.4598 - val_mae: 943.9594 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 903.4767 - mae: 903.9763 - val_loss: 892.9826 - val_mae: 893.4822 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 865.3278 - mae: 865.8275 - val_loss: 825.4742 - val_mae: 825.9737 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 830.9634 - mae: 831.4630 - val_loss: 813.2333 - val_mae: 813.7330 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 803.2933 - mae: 803.7928 - val_loss: 777.5411 - val_mae: 778.0408 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 773.8408 - mae: 774.3404 - val_loss: 779.9053 - val_mae: 780.4045 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 751.7276 - mae: 752.2275 - val_loss: 742.6984 - val_mae: 743.1983 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 728.7275 - mae: 729.2271 - val_loss: 719.7816 - val_mae: 720.2810 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 712.3433 - mae: 712.8427 - val_loss: 701.2846 - val_mae: 701.7839 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 696.6987 - mae: 697.1983 - val_loss: 683.3140 - val_mae: 683.8135 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 687.8788 - mae: 688.3782 - val_loss: 662.2488 - val_mae: 662.7485 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 676.7036 - mae: 677.2033 - val_loss: 658.2261 - val_mae: 658.7256 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 666.4628 - mae: 666.9625 - val_loss: 655.1714 - val_mae: 655.6713 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 659.8657 - mae: 660.3651 - val_loss: 643.3771 - val_mae: 643.8768 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 652.1880 - mae: 652.6876 - val_loss: 630.9941 - val_mae: 631.4939 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 648.7275 - mae: 649.2272 - val_loss: 628.4163 - val_mae: 628.9155 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 642.8701 - mae: 643.3695 - val_loss: 626.9490 - val_mae: 627.4484 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 640.6489 - mae: 641.1487 - val_loss: 619.6920 - val_mae: 620.1917 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 633.8442 - mae: 634.3439 - val_loss: 618.5085 - val_mae: 619.0082 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 632.3391 - mae: 632.8388 - val_loss: 621.4617 - val_mae: 621.9614 - learning_rate: 0.0010\n",
      "Epoch 46/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 627.6035 - mae: 628.1033 - val_loss: 622.1190 - val_mae: 622.6185 - learning_rate: 0.0010\n",
      "Epoch 47/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 621.7955 - mae: 622.2952 - val_loss: 617.3323 - val_mae: 617.8315 - learning_rate: 0.0010\n",
      "Epoch 48/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 622.7421 - mae: 623.2419 - val_loss: 620.5598 - val_mae: 621.0596 - learning_rate: 0.0010\n",
      "Epoch 49/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 622.4380 - mae: 622.9375 - val_loss: 621.7345 - val_mae: 622.2344 - learning_rate: 0.0010\n",
      "Epoch 50/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 618.7290 - mae: 619.2286 - val_loss: 621.3002 - val_mae: 621.7997 - learning_rate: 0.0010\n",
      "Epoch 51/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 615.5469 - mae: 616.0467 - val_loss: 616.8721 - val_mae: 617.3721 - learning_rate: 0.0010\n",
      "Epoch 52/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616.5621 - mae: 617.0618 - val_loss: 616.3710 - val_mae: 616.8702 - learning_rate: 0.0010\n",
      "Epoch 53/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610.9587 - mae: 611.4584 - val_loss: 612.5174 - val_mae: 613.0173 - learning_rate: 0.0010\n",
      "Epoch 54/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 613.6871 - mae: 614.1867 - val_loss: 613.4644 - val_mae: 613.9639 - learning_rate: 0.0010\n",
      "Epoch 55/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610.0734 - mae: 610.5729 - val_loss: 616.9445 - val_mae: 617.4440 - learning_rate: 0.0010\n",
      "Epoch 56/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 609.7833 - mae: 610.2830 - val_loss: 617.1252 - val_mae: 617.6248 - learning_rate: 0.0010\n",
      "Epoch 57/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 611.8908 - mae: 612.3904 - val_loss: 616.9612 - val_mae: 617.4609 - learning_rate: 0.0010\n",
      "Epoch 58/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603.1450 - mae: 603.6447 - val_loss: 612.6677 - val_mae: 613.1672 - learning_rate: 0.0010\n",
      "Epoch 59/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 600.7032 - mae: 601.2029 - val_loss: 610.5392 - val_mae: 611.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 595.1697 - mae: 595.6693 - val_loss: 610.9728 - val_mae: 611.4724 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 595.5789 - mae: 596.0784 - val_loss: 607.5631 - val_mae: 608.0624 - learning_rate: 5.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593.0134 - mae: 593.5129 - val_loss: 608.8266 - val_mae: 609.3258 - learning_rate: 5.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 591.7261 - mae: 592.2257 - val_loss: 611.5325 - val_mae: 612.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 591.2753 - mae: 591.7748 - val_loss: 608.2645 - val_mae: 608.7642 - learning_rate: 5.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590.3066 - mae: 590.8063 - val_loss: 608.3845 - val_mae: 608.8843 - learning_rate: 5.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 588.5847 - mae: 589.0842 - val_loss: 606.7812 - val_mae: 607.2809 - learning_rate: 5.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589.4072 - mae: 589.9067 - val_loss: 609.0645 - val_mae: 609.5640 - learning_rate: 5.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 588.3036 - mae: 588.8033 - val_loss: 609.8489 - val_mae: 610.3486 - learning_rate: 5.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586.6633 - mae: 587.1628 - val_loss: 607.3334 - val_mae: 607.8334 - learning_rate: 5.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585.7454 - mae: 586.2452 - val_loss: 608.0725 - val_mae: 608.5720 - learning_rate: 5.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 585.5055 - mae: 586.0051 - val_loss: 605.3481 - val_mae: 605.8478 - learning_rate: 5.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585.0384 - mae: 585.5377 - val_loss: 606.4622 - val_mae: 606.9619 - learning_rate: 5.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 581.4500 - mae: 581.9494 - val_loss: 601.6581 - val_mae: 602.1580 - learning_rate: 5.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585.0155 - mae: 585.5153 - val_loss: 608.6248 - val_mae: 609.1246 - learning_rate: 5.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.6782 - mae: 580.1778 - val_loss: 605.0754 - val_mae: 605.5751 - learning_rate: 5.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.5555 - mae: 580.0552 - val_loss: 606.5569 - val_mae: 607.0565 - learning_rate: 5.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 581.1058 - mae: 581.6053 - val_loss: 606.1605 - val_mae: 606.6601 - learning_rate: 5.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.6252 - mae: 580.1249 - val_loss: 605.7209 - val_mae: 606.2206 - learning_rate: 5.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 578.5014 - mae: 579.0010 - val_loss: 603.9410 - val_mae: 604.4408 - learning_rate: 2.5000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577.5252 - mae: 578.0247 - val_loss: 603.7228 - val_mae: 604.2222 - learning_rate: 2.5000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574.5859 - mae: 575.0855 - val_loss: 604.8685 - val_mae: 605.3682 - learning_rate: 2.5000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 571.9984 - mae: 572.4979 - val_loss: 602.0029 - val_mae: 602.5025 - learning_rate: 2.5000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573.6440 - mae: 574.1434 - val_loss: 603.5277 - val_mae: 604.0275 - learning_rate: 2.5000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 572.0261 - mae: 572.5258 - val_loss: 602.3360 - val_mae: 602.8358 - learning_rate: 1.2500e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 570.1497 - mae: 570.6495 - val_loss: 601.5240 - val_mae: 602.0239 - learning_rate: 1.2500e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569.0945 - mae: 569.5941 - val_loss: 602.3237 - val_mae: 602.8229 - learning_rate: 1.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 568.7350 - mae: 569.2346 - val_loss: 600.3489 - val_mae: 600.8480 - learning_rate: 1.2500e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.3702 - mae: 568.8696 - val_loss: 601.1095 - val_mae: 601.6092 - learning_rate: 1.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.4346 - mae: 568.9342 - val_loss: 601.7037 - val_mae: 602.2036 - learning_rate: 1.2500e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.9227 - mae: 569.4222 - val_loss: 599.8959 - val_mae: 600.3949 - learning_rate: 1.2500e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 567.3570 - mae: 567.8564 - val_loss: 600.2286 - val_mae: 600.7282 - learning_rate: 1.2500e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564.0436 - mae: 564.5434 - val_loss: 599.4087 - val_mae: 599.9081 - learning_rate: 1.2500e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566.3124 - mae: 566.8120 - val_loss: 599.3715 - val_mae: 599.8709 - learning_rate: 1.2500e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565.3255 - mae: 565.8252 - val_loss: 600.5354 - val_mae: 601.0347 - learning_rate: 1.2500e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 569.8901 - mae: 570.3896 - val_loss: 600.5588 - val_mae: 601.0580 - learning_rate: 1.2500e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569.8354 - mae: 570.3350 - val_loss: 600.7019 - val_mae: 601.2008 - learning_rate: 1.2500e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 571.3474 - mae: 571.8470 - val_loss: 599.8669 - val_mae: 600.3662 - learning_rate: 1.2500e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564.2562 - mae: 564.7557 - val_loss: 599.7053 - val_mae: 600.2053 - learning_rate: 1.2500e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565.9372 - mae: 566.4368 - val_loss: 599.8485 - val_mae: 600.3478 - learning_rate: 6.2500e-05\n",
      "Epoch 100/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570.4099 - mae: 570.9094 - val_loss: 600.7255 - val_mae: 601.2249 - learning_rate: 6.2500e-05\n",
      "Epoch 101/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563.5714 - mae: 564.0712 - val_loss: 600.0696 - val_mae: 600.5692 - learning_rate: 6.2500e-05\n",
      "Epoch 102/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 566.7326 - mae: 567.2321 - val_loss: 599.9672 - val_mae: 600.4669 - learning_rate: 6.2500e-05\n",
      "Epoch 103/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.6678 - mae: 569.1675 - val_loss: 601.2387 - val_mae: 601.7380 - learning_rate: 6.2500e-05\n",
      "Epoch 104/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566.4299 - mae: 566.9295 - val_loss: 600.5291 - val_mae: 601.0287 - learning_rate: 3.1250e-05\n",
      "Epoch 105/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565.1012 - mae: 565.6010 - val_loss: 600.3173 - val_mae: 600.8168 - learning_rate: 3.1250e-05\n",
      "Epoch 106/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564.2323 - mae: 564.7319 - val_loss: 600.8025 - val_mae: 601.3019 - learning_rate: 3.1250e-05\n",
      "Epoch 107/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565.7841 - mae: 566.2838 - val_loss: 600.6009 - val_mae: 601.1009 - learning_rate: 3.1250e-05\n",
      "Epoch 108/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 564.8752 - mae: 565.3747 - val_loss: 600.6240 - val_mae: 601.1236 - learning_rate: 3.1250e-05\n",
      "Epoch 109/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562.4164 - mae: 562.9160 - val_loss: 600.2471 - val_mae: 600.7468 - learning_rate: 1.5625e-05\n",
      "Epoch 110/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562.7372 - mae: 563.2368 - val_loss: 600.0239 - val_mae: 600.5236 - learning_rate: 1.5625e-05\n",
      "Epoch 111/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565.5217 - mae: 566.0210 - val_loss: 600.0789 - val_mae: 600.5786 - learning_rate: 1.5625e-05\n",
      "Epoch 112/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563.4134 - mae: 563.9129 - val_loss: 600.1995 - val_mae: 600.6990 - learning_rate: 1.5625e-05\n",
      "Epoch 113/300\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562.9556 - mae: 563.4551 - val_loss: 600.7427 - val_mae: 601.2421 - learning_rate: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=300,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "489b5aed-9cc6-4428-903f-2ffd51ed7699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Test MSE: 939643.9152067989\n",
      "Test MAE: 605.347353463248\n",
      "Test RMSE: 969.3523173783611\n",
      "RMSE Ratio: 0.5187200946226167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "# Compute metrics\n",
    "mse  = mean_squared_error(y_test, y_pred)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse_ratio = rmse / y_test.mean()\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"RMSE Ratio:\", rmse_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed4993d6-84dd-4191-ac2c-17a9f0b336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMAGE LOADER\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = preprocess_input(img)   # EfficientNet preprocessing (required)\n",
    "    return img, label\n",
    "\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((df_train_cnn[\"image_path\"], df_train_cnn[\"price_numeric\"]))\n",
    "    .map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1024)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((df_val_cnn[\"image_path\"], df_val_cnn[\"price_numeric\"]))\n",
    "    .map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((df_test_cnn[\"image_path\"], df_test_cnn[\"price_numeric\"]))\n",
    "    .map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "842dffc2-4338-4114-b1c5-a7ba86629359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m327,936\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,394,020</span> (16.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,394,020\u001b[0m (16.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">344,449</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m344,449\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base = EfficientNetB0(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "base.trainable = False   # Freeze EfficientNet base\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4287e489-8c7b-433e-b2c6-2ccd8ec4dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 844ms/step - loss: 1668.4501 - mae: 1668.4501 - val_loss: 1257.8141 - val_mae: 1257.8141\n",
      "Epoch 2/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 773ms/step - loss: 1159.5308 - mae: 1159.5308 - val_loss: 1079.5375 - val_mae: 1079.5375\n",
      "Epoch 3/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 765ms/step - loss: 1101.0612 - mae: 1101.0612 - val_loss: 1060.6377 - val_mae: 1060.6377\n",
      "Epoch 4/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 763ms/step - loss: 1082.2972 - mae: 1082.2972 - val_loss: 1047.2738 - val_mae: 1047.2738\n",
      "Epoch 5/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 765ms/step - loss: 1069.6781 - mae: 1069.6781 - val_loss: 1036.9413 - val_mae: 1036.9413\n",
      "Epoch 6/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 765ms/step - loss: 1059.9360 - mae: 1059.9360 - val_loss: 1027.9498 - val_mae: 1027.9498\n",
      "Epoch 7/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 760ms/step - loss: 1047.4648 - mae: 1047.4648 - val_loss: 1020.2065 - val_mae: 1020.2065\n",
      "Epoch 8/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 761ms/step - loss: 1040.9860 - mae: 1040.9860 - val_loss: 1013.7089 - val_mae: 1013.7089\n",
      "Epoch 9/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 764ms/step - loss: 1031.0149 - mae: 1031.0149 - val_loss: 1007.7657 - val_mae: 1007.7657\n",
      "Epoch 10/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 766ms/step - loss: 1024.4833 - mae: 1024.4833 - val_loss: 1002.4254 - val_mae: 1002.4254\n",
      "Epoch 11/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 767ms/step - loss: 1019.7657 - mae: 1019.7657 - val_loss: 997.5005 - val_mae: 997.5005\n",
      "Epoch 12/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 767ms/step - loss: 1010.0328 - mae: 1010.0328 - val_loss: 993.1950 - val_mae: 993.1950\n",
      "Epoch 13/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 764ms/step - loss: 1007.0120 - mae: 1007.0120 - val_loss: 989.8640 - val_mae: 989.8640\n",
      "Epoch 14/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 759ms/step - loss: 1004.0261 - mae: 1004.0261 - val_loss: 986.5343 - val_mae: 986.5343\n",
      "Epoch 15/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 759ms/step - loss: 1001.4521 - mae: 1001.4521 - val_loss: 983.8932 - val_mae: 983.8932\n",
      "Epoch 16/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 758ms/step - loss: 995.1732 - mae: 995.1732 - val_loss: 981.2742 - val_mae: 981.2742\n",
      "Epoch 17/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 760ms/step - loss: 996.9218 - mae: 996.9218 - val_loss: 978.9521 - val_mae: 978.9521\n",
      "Epoch 18/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 760ms/step - loss: 989.5347 - mae: 989.5347 - val_loss: 976.9858 - val_mae: 976.9858\n",
      "Epoch 19/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 760ms/step - loss: 987.9373 - mae: 987.9373 - val_loss: 975.6329 - val_mae: 975.6329\n",
      "Epoch 20/20\n",
      "\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 761ms/step - loss: 983.5844 - mae: 983.5844 - val_loss: 973.9943 - val_mae: 973.9943\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"mae\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37d0f6e3-c985-461c-b642-accc9cb6c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 705ms/step\n",
      "Test MSE: 1961648.8768552984\n",
      "Test MAE: 998.8659815372393\n",
      "Test RMSE: 1400.588760791439\n",
      "RMSE Ratio: 0.7494834659187525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(test_ds).ravel()\n",
    "\n",
    "# True values\n",
    "y_true = df_test_cnn[\"price_numeric\"].values\n",
    "\n",
    "# Metrics\n",
    "mse  = mean_squared_error(y_true, y_pred)\n",
    "mae  = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse_ratio = rmse / y_true.mean()\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"RMSE Ratio:\", rmse_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1334af76-eb50-4b76-9751-46b32ee16828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save(\"CNN.h5\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16c3952f-6fb2-4040-8463-02414b878f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m327,936\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,082,920</span> (19.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,082,920\u001b[0m (19.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">344,449</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m344,449\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">688,900</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m688,900\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
